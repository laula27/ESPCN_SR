{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJD6aShw6tYy"
      },
      "source": [
        "## README\n",
        "\n",
        "This part is for testing image, the dataset is using Set 5 to test on the performance through this website(https://deepai.org/dataset/set5-super-resolution)\n",
        "\n",
        "The weighted file should be download through (https://github.com/spmallick/learnopencv.git) in the Super-Resolution-in-OpenCV folder. \n",
        "Make sure to download the dataset in the images directory, the result will show in the image folder as well. \n",
        "\n",
        "Changes:\n",
        "\n",
        "I had changed the overall structure and the model.\n",
        "\n",
        "### Note\n",
        "\n",
        "If this code had run before the result image will be in the same folder, so you might need to delete the result image before run this program again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0VwWlECIn0_",
        "outputId": "8c68f526-6de8-4340-be4a-b2a291519ae3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1ZxV2LaZfzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b43805b-4cc0-495b-ddd9-997d05f05517"
      },
      "source": [
        "import argparse\n",
        "\n",
        "import tensorflow as tf\n",
        "import math\n",
        "from os import listdir\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import PIL.Image as pil_image \n",
        "from PIL import ImageFile, ImageDraw, ImageChops, ImageFilter\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class ESPCN(nn.Module):\n",
        "    def __init__(self, scale_factor, num_channels=1):\n",
        "        super(ESPCN, self).__init__()\n",
        "        self.first_part = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, 64, kernel_size=5, padding=5//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=3//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=3//2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.last_part = nn.Sequential(\n",
        "            nn.Conv2d(32, num_channels * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\n",
        "            nn.PixelShuffle(scale_factor)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m.in_channels == 32:\n",
        "                    nn.init.normal_(m.weight.data, mean=0.0, std=0.001)\n",
        "                    nn.init.zeros_(m.bias.data)\n",
        "                else:\n",
        "                    nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
        "                    nn.init.zeros_(m.bias.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first_part(x)\n",
        "        x = self.last_part(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def calc_patch_size(func):\n",
        "    def wrapper(args):\n",
        "        if args.scale == 2:\n",
        "            args.patch_size = 10\n",
        "        elif args.scale == 3:\n",
        "            args.patch_size = 7\n",
        "        elif args.scale == 4:\n",
        "            args.patch_size = 6\n",
        "        else:\n",
        "            raise Exception('Scale Error', args.scale)\n",
        "        return func(args)\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def convert_rgb_to_y(img, dim_order='hwc'):\n",
        "    if dim_order == 'hwc':\n",
        "        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n",
        "    else:\n",
        "        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n",
        "\n",
        "\n",
        "def convert_rgb_to_ycbcr(img, dim_order='hwc'):\n",
        "    if dim_order == 'hwc':\n",
        "        y = 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n",
        "        cb = 128. + (-37.945 * img[..., 0] - 74.494 * img[..., 1] + 112.439 * img[..., 2]) / 256.\n",
        "        cr = 128. + (112.439 * img[..., 0] - 94.154 * img[..., 1] - 18.285 * img[..., 2]) / 256.\n",
        "    else:\n",
        "        y = 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n",
        "        cb = 128. + (-37.945 * img[0] - 74.494 * img[1] + 112.439 * img[2]) / 256.\n",
        "        cr = 128. + (112.439 * img[0] - 94.154 * img[1] - 18.285 * img[2]) / 256.\n",
        "    return np.array([y, cb, cr]).transpose([1, 2, 0])\n",
        "\n",
        "\n",
        "def convert_ycbcr_to_rgb(img, dim_order='hwc'):\n",
        "    if dim_order == 'hwc':\n",
        "        r = 298.082 * img[..., 0] / 256. + 408.583 * img[..., 2] / 256. - 222.921\n",
        "        g = 298.082 * img[..., 0] / 256. - 100.291 * img[..., 1] / 256. - 208.120 * img[..., 2] / 256. + 135.576\n",
        "        b = 298.082 * img[..., 0] / 256. + 516.412 * img[..., 1] / 256. - 276.836\n",
        "    else:\n",
        "        r = 298.082 * img[0] / 256. + 408.583 * img[2] / 256. - 222.921\n",
        "        g = 298.082 * img[0] / 256. - 100.291 * img[1] / 256. - 208.120 * img[2] / 256. + 135.576\n",
        "        b = 298.082 * img[0] / 256. + 516.412 * img[1] / 256. - 276.836\n",
        "    return np.array([r, g, b]).transpose([1, 2, 0])\n",
        "\n",
        "\n",
        "def preprocess(img, device):\n",
        "    img = np.array(img).astype(np.float32)\n",
        "    ycbcr = convert_rgb_to_ycbcr(img)\n",
        "    x = ycbcr[..., 0]\n",
        "    x /= 255.\n",
        "    x = torch.from_numpy(x).to(device)\n",
        "    x = x.unsqueeze(0).unsqueeze(0)\n",
        "    return x, ycbcr\n",
        "\n",
        "\n",
        "def calc_psnr(img1, img2):\n",
        "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "import math\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class ESPCN(nn.Module):\n",
        "    def __init__(self, scale_factor, num_channels=1):\n",
        "        super(ESPCN, self).__init__()\n",
        "        self.first_part = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, 64, kernel_size=5, padding=5//2),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=3//2),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.last_part = nn.Sequential(\n",
        "            nn.Conv2d(32, num_channels * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\n",
        "            nn.PixelShuffle(scale_factor)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m.in_channels == 32:\n",
        "                    nn.init.normal_(m.weight.data, mean=0.0, std=0.001)\n",
        "                    nn.init.zeros_(m.bias.data)\n",
        "                else:\n",
        "                    nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
        "                    nn.init.zeros_(m.bias.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first_part(x)\n",
        "        x = self.last_part(x)\n",
        "        return x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    weights_file = '/content/drive/MyDrive/ECE570Project/ESPCNV1/espcn_x3.pth'\n",
        "    image_file = '/content/drive/MyDrive/ECE570Project/ESPCNV1/images/'\n",
        "    scale = 3\n",
        "    images_name = [x for x in listdir(image_file)]\n",
        "\n",
        "    total_test_psnr = 0.0\n",
        "    cudnn.benchmark = True\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = ESPCN(scale_factor=scale).to(device)\n",
        "\n",
        "    state_dict = model.state_dict()\n",
        "    for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n",
        "        if n in state_dict.keys():\n",
        "            state_dict[n].copy_(p)\n",
        "        else:\n",
        "            raise KeyError(n)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    for image_name in tqdm(images_name):\n",
        "        image = pil_image.open(image_file + image_name).convert('RGB')\n",
        "\n",
        "        image_width = (image.width // scale) * scale\n",
        "        image_height = (image.height // scale) * scale\n",
        "\n",
        "        hr = image.resize((image_width, image_height))\n",
        "        img_blur = hr.copy()\n",
        "        lowres_input = img_blur.filter(ImageFilter.GaussianBlur)\n",
        "\n",
        "        lr = lowres_input.resize((hr.width // scale, hr.height // scale))\n",
        "        bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n",
        "        bicubic.save(image_file+image_name.replace('.', '_bicubic_x{}.'.format(scale)))\n",
        "\n",
        "        lr, _ = preprocess(lr, device)\n",
        "        hr, _ = preprocess(hr, device)\n",
        "        _, ycbcr = preprocess(bicubic, device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(lr).clamp(0.0, 1.0)\n",
        "\n",
        "        psnr = calc_psnr(hr, preds)\n",
        "        total_test_psnr+=psnr\n",
        "        \n",
        "        \n",
        "        print('PSNR: {:.2f}'.format(psnr))\n",
        "\n",
        "        preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
        "\n",
        "        output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
        "        output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
        "        output = pil_image.fromarray(output)\n",
        "        output.save(image_file+image_name.replace('.', '_espcn_x{}.'.format(scale)))\n",
        "lens = len(images_name)\n",
        "print(\"Avg. PSNR of lowres images is %.4f\" % (total_test_psnr / lens))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 1/17 [00:01<00:17,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 27.35\n",
            "PSNR: 22.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 2/17 [00:03<00:30,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 22.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 3/17 [00:06<00:29,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 31.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 4/17 [00:08<00:28,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 31.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 8/17 [00:10<00:07,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 34.63\n",
            "PSNR: 33.69\n",
            "PSNR: 39.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 10/17 [00:10<00:03,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 38.48\n",
            "PSNR: 40.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 13/17 [00:10<00:00,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 39.45\n",
            "PSNR: 43.42\n",
            "PSNR: 42.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 14/17 [00:11<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 35.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 15/17 [00:12<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 35.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 16/17 [00:12<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 35.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17/17 [00:13<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 34.92\n",
            "Avg. PSNR of lowres images is 34.6073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}